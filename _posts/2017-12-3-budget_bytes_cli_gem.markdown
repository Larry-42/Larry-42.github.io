---
layout: post
title:      "CLI Ruby Gem:  Budget Bytes CLI"
date:       2017-12-3 14:30:00 +0000
permalink:  budget_bytes_cli_gem
---


For my CLI Ruby project, I decided to create a CLI application that accessed one of my favorite recipe blogs ever, [Budget Bytes](http:///www.budgetbytes.com).  I also decided that my application should have a feature that extends the blog's functionality--the ability to combine recipe categories.  The blog's recipes are organized into categories, and I though that it would be nice to be able to see what recipes intersected two categories.  A bit ambitious for this project?  Perhaps.  But once I set my mind to the project, I wanted to see things through.

If you're looking for a site to scrape for your CLI Gem project, one of the most important things to do is to make sure that it's relatively scraper-friendly; there are sites that aren't!  The first thing that I did before starting the project was to see if Budget Bytes was scrapable; as luck would have it, the site is all but made to be scraped.  Just about everything Iuseful for a scraper--recipe ingredients, recipes instructions, recipe pages, recipe categories, page numbers--has its own class on the relevant webpage.  Everything on this site is scrapable with (relatively) little effort using Nokogiri.  At least that's what I thought (more on that later...)

With that out of the way, I ran `bundle gem budget_bytes_cli` (dashes in the gem name do not end well when you run `bundle gem`), and synced my local Git repository with a new Github project.  Then I setup the Ruby environment to allow nokogiri and pry use, and started out with classes for recipes, categories, and a scraper whose purpose is to scrape the recipe categories.  After figuring out how to scrape the recipe categories, including the list of recipes across multiple pages, I started developing the interface.  

The interface was based on the need to select from large arrays.  Budget Bytes has 46 recipe categories, and many of the categories have well over 100 recipes.  So, I ended up creating a class which prompts and has the user select from an array.  And I had two instances of this class (ArraySelector) in another class (ArrayPrompter) which lets the user select from a block of items (1-20, 21-40, *etc*).  I used this class within my CLI class to prompt the user to select a recipe category, and select a recipe to display.

At this point, I started refactoring, fixing bugs, and adding features.  I made the recipe instructions word-wrap on the terminal display, and added the ability to display recipe pages through Launchy (which meant I had to include io/console and to include Launchy as a dependency.)  Then, I implemented the feature mssing from the blog that I noted earlier--combining categories.  I added a function to my Category class to combine recipes with another category (returning an array of recipes which are in both categories), and modified my CLI to allow the new feature.  After a quick bit of debugging, I decided that my project was "good enough"--after another round of bug fixing that is. 

After that, I dotted my i's can crossed my t's so to speak to turn the program into a gem.  That last bit was tougher than I had expected.  I had to fiddle with the gemspec a bit to, among other things, enable running the gem when it was installed using gem install.  But, I kept on getting an error that said--among many, many other things--"cannot load such file -- ../config/environment (LoadError)". After messing around with the gemspec a bit and getting nowhere, I traced this back to where I'd required one of my files.  Sure enough, I'd used `require` instead of `require_relative`.  So, the program worked in my development directory, but not when run as a gem!  I fixed this, and finally had a working (and hopefully somewhat presentable) CLI gem.

Or so I thought.  Remember how I mentioned that it looked like the site was essentially made to be scraped?  It turned out that the website had switched formats sometime shortly after it was created.  As you might guess, the change in CSS broke the scraper.  It turned out that there were table elements that existed on the old site format that didn't make the transition to the new one--I refactored to scrape these to allow the older recipes to be scraped.  And added an error message for recipes the site couldn't scrape just to be on the safe side!

Overall, this project took longer than I expected (the first half of the project took about 90% of the allotted time, and the second half took the other 90%).  And while I setup the project as best I could, and it does what I hoped it would, I'm still a bit worried about my code quality.  Nothing really jumps out at me, but I get a nagging feeling that there are some things that could be improved.  I'll give you all an update after the assessment...

In case you're curious, the proejct lives at [GitHub](http://github.com/Larry-42/budget-bytes-cli).  If you're looking at starting your CLI gem, there are a few things to keep in mind.  It can and will take longer than you thought.  You need to look at how the site is structured before beginning the project.  And you WILL run into issues you didn't expect.  While I am aware that this post was a bit long, I wanted to provide an idea of the sorts of things that can go wrong in a project like this--and show that the errors you run into aren't impossible to fix.
